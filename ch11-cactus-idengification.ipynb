{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 11장 항공 사진 내 선인장 식별 경진대회\n\n## 1. 탐색적 데이터 분석\n### 1) 데이터 둘러보기","metadata":{"papermill":{"duration":0.01747,"end_time":"2021-07-31T06:57:35.274085","exception":false,"start_time":"2021-07-31T06:57:35.256615","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import pandas as pd\n\ndata_path = '/kaggle/input/aerial-cactus-identification/'\n\nlabels = pd.read_csv(data_path + 'train.csv')\nsubmission = pd.read_csv(data_path + 'sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:29:08.934829Z","iopub.execute_input":"2023-10-29T10:29:08.935122Z","iopub.status.idle":"2023-10-29T10:29:09.087333Z","shell.execute_reply.started":"2023-10-29T10:29:08.935045Z","shell.execute_reply":"2023-10-29T10:29:09.086655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:29:09.088573Z","iopub.execute_input":"2023-10-29T10:29:09.088791Z","iopub.status.idle":"2023-10-29T10:29:09.109340Z","shell.execute_reply.started":"2023-10-29T10:29:09.088764Z","shell.execute_reply":"2023-10-29T10:29:09.108511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:29:09.110272Z","iopub.execute_input":"2023-10-29T10:29:09.110495Z","iopub.status.idle":"2023-10-29T10:29:09.120425Z","shell.execute_reply.started":"2023-10-29T10:29:09.110470Z","shell.execute_reply":"2023-10-29T10:29:09.119596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2) 데이터 시각화\n\n타깃값 분포","metadata":{}},{"cell_type":"code","source":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nmpl.rc('font', size=15)\nplt.figure(figsize=(7, 7))\n\nlabel = ['Has cactus', 'Hasn\\'t cactus']\n\nplt.pie(labels['has_cactus'].value_counts(), labels=label, autopct='%.1f%%')","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:29:09.122506Z","iopub.execute_input":"2023-10-29T10:29:09.122831Z","iopub.status.idle":"2023-10-29T10:29:09.265665Z","shell.execute_reply.started":"2023-10-29T10:29:09.122797Z","shell.execute_reply":"2023-10-29T10:29:09.264986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"이미지 출력","metadata":{}},{"cell_type":"code","source":"from zipfile import ZipFile\n\nwith ZipFile(data_path + 'train.zip') as zipper:\n    zipper.extractall()\n    \nwith ZipFile(data_path + 'test.zip') as zipper:\n    zipper.extractall()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:29:09.266691Z","iopub.execute_input":"2023-10-29T10:29:09.266927Z","iopub.status.idle":"2023-10-29T10:29:12.508995Z","shell.execute_reply.started":"2023-10-29T10:29:09.266900Z","shell.execute_reply":"2023-10-29T10:29:12.508381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nnum_train = len(os.listdir('train/'))\nnum_test = len(os.listdir('test/'))\n\nprint(f'훈련 데이터 개수 : {num_train}')\nprint(f'테스트 데이터 개수 : {num_test}')","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:29:12.510347Z","iopub.execute_input":"2023-10-29T10:29:12.510630Z","iopub.status.idle":"2023-10-29T10:29:12.531483Z","shell.execute_reply.started":"2023-10-29T10:29:12.510593Z","shell.execute_reply":"2023-10-29T10:29:12.530701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.gridspec as gridspec\nimport cv2\n\nmpl.rc('font', size=7)\nplt.figure(figsize=(15, 6))\ngrid = gridspec.GridSpec(2, 6)\n\nlast_has_cactus_img_name = labels[labels['has_cactus']==1]['id'][-12:]\n\nfor idx, img_name in enumerate(last_has_cactus_img_name):\n    img_path = 'train/' + img_name\n    image = cv2.imread(img_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    ax = plt.subplot(grid[idx])\n    ax.imshow(image)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:29:12.532544Z","iopub.execute_input":"2023-10-29T10:29:12.532774Z","iopub.status.idle":"2023-10-29T10:29:14.401630Z","shell.execute_reply.started":"2023-10-29T10:29:12.532746Z","shell.execute_reply":"2023-10-29T10:29:14.400838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 6))\ngrid = gridspec.GridSpec(2, 6)\nlast_hasnt_cactus_img_name = labels[labels['has_cactus']==0]['id'][-12:]\n\nfor idx, img_name in enumerate(last_hasnt_cactus_img_name):\n    img_path = 'train/' + img_name\n    image = cv2.imread(img_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    ax = plt.subplot(grid[idx])\n    ax.imshow(image)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:29:14.402747Z","iopub.execute_input":"2023-10-29T10:29:14.402978Z","iopub.status.idle":"2023-10-29T10:29:16.037842Z","shell.execute_reply.started":"2023-10-29T10:29:14.402950Z","shell.execute_reply":"2023-10-29T10:29:16.036765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:29:16.039610Z","iopub.execute_input":"2023-10-29T10:29:16.040100Z","iopub.status.idle":"2023-10-29T10:29:16.051453Z","shell.execute_reply.started":"2023-10-29T10:29:16.040031Z","shell.execute_reply":"2023-10-29T10:29:16.050193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. 베이스라인 모델\n### 1) 시드값 고정 및 GPU 장비 설정","metadata":{}},{"cell_type":"code","source":"import torch\nimport random\nimport numpy as np\nimport os\n\nseed = 50\nos.environ['PYTHONHASHSEED'] = str(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.enabled = False","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:29:16.055096Z","iopub.execute_input":"2023-10-29T10:29:16.055790Z","iopub.status.idle":"2023-10-29T10:29:20.706127Z","shell.execute_reply.started":"2023-10-29T10:29:16.055749Z","shell.execute_reply":"2023-10-29T10:29:20.705238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if torch.cuda.is_available():\n#     device = torch.device('cuda')\n# else:\n#     device = torch.device('cpu')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:29:20.707340Z","iopub.execute_input":"2023-10-29T10:29:20.707596Z","iopub.status.idle":"2023-10-29T10:29:20.802238Z","shell.execute_reply.started":"2023-10-29T10:29:20.707565Z","shell.execute_reply":"2023-10-29T10:29:20.801439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2) 데이터 준비","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndata_path = '/kaggle/input/aerial-cactus-identification/'\n\nlabels = pd.read_csv(data_path + 'train.csv')\nsubmission = pd.read_csv(data_path + 'sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:29:20.803403Z","iopub.execute_input":"2023-10-29T10:29:20.803654Z","iopub.status.idle":"2023-10-29T10:29:20.838552Z","shell.execute_reply.started":"2023-10-29T10:29:20.803626Z","shell.execute_reply":"2023-10-29T10:29:20.837959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from zipfile import ZipFile\n\nwith ZipFile(data_path + 'train.zip') as zipper:\n    zipper.extractall()\n    \nwith ZipFile(data_path + 'test.zip') as zipper:\n    zipper.extractall()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:29:20.839470Z","iopub.execute_input":"2023-10-29T10:29:20.839680Z","iopub.status.idle":"2023-10-29T10:29:24.755923Z","shell.execute_reply.started":"2023-10-29T10:29:20.839655Z","shell.execute_reply":"2023-10-29T10:29:24.755240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"훈련 데이터, 검증 데이터 분리","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain, valid = train_test_split(labels, test_size=0.1, stratify=labels['has_cactus'], random_state=50)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:29:24.756985Z","iopub.execute_input":"2023-10-29T10:29:24.757273Z","iopub.status.idle":"2023-10-29T10:29:25.508210Z","shell.execute_reply.started":"2023-10-29T10:29:24.757236Z","shell.execute_reply":"2023-10-29T10:29:25.507509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'훈련 데이터 개수 : {len(train)}')\nprint(f'검증 데이터 개수 : {len(valid)}')","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:29:25.509383Z","iopub.execute_input":"2023-10-29T10:29:25.509678Z","iopub.status.idle":"2023-10-29T10:29:25.514659Z","shell.execute_reply.started":"2023-10-29T10:29:25.509640Z","shell.execute_reply":"2023-10-29T10:29:25.513766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"데이터셋 클래스 정의","metadata":{}},{"cell_type":"code","source":"import cv2\nfrom torch.utils.data import Dataset","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:29:25.515720Z","iopub.execute_input":"2023-10-29T10:29:25.515987Z","iopub.status.idle":"2023-10-29T10:29:25.526984Z","shell.execute_reply.started":"2023-10-29T10:29:25.515953Z","shell.execute_reply":"2023-10-29T10:29:25.526228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImageDataset(Dataset):\n    def __init__(self, df, img_dir='./', transform=None):\n        super().__init__()\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        img_id = self.df.iloc[idx, 0]\n        img_path = self.img_dir + img_id\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        label = self.df.iloc[idx, 1]\n        \n        if self.transform is not None:\n            image = self.transform(image)\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:29:25.528257Z","iopub.execute_input":"2023-10-29T10:29:25.528593Z","iopub.status.idle":"2023-10-29T10:29:25.537399Z","shell.execute_reply.started":"2023-10-29T10:29:25.528558Z","shell.execute_reply":"2023-10-29T10:29:25.536722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"데이터셋 생성","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms\n\ntransform = transforms.ToTensor()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:29:25.538467Z","iopub.execute_input":"2023-10-29T10:29:25.538683Z","iopub.status.idle":"2023-10-29T10:29:25.688700Z","shell.execute_reply.started":"2023-10-29T10:29:25.538659Z","shell.execute_reply":"2023-10-29T10:29:25.687836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_train = ImageDataset(df=train, img_dir='train/',transform=transform)\ndataset_valid = ImageDataset(df=valid, img_dir='train/',transform=transform)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:29:25.690483Z","iopub.execute_input":"2023-10-29T10:29:25.690719Z","iopub.status.idle":"2023-10-29T10:29:25.695582Z","shell.execute_reply.started":"2023-10-29T10:29:25.690692Z","shell.execute_reply":"2023-10-29T10:29:25.694675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"데이터 로더 생성","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nloader_train = DataLoader(dataset=dataset_train, batch_size=32, shuffle=True)\nloader_valid = DataLoader(dataset=dataset_valid, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:29:25.696489Z","iopub.execute_input":"2023-10-29T10:29:25.696725Z","iopub.status.idle":"2023-10-29T10:29:25.709512Z","shell.execute_reply.started":"2023-10-29T10:29:25.696699Z","shell.execute_reply":"2023-10-29T10:29:25.708821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3) 모델 생성","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:29:25.710840Z","iopub.execute_input":"2023-10-29T10:29:25.711054Z","iopub.status.idle":"2023-10-29T10:29:25.720098Z","shell.execute_reply.started":"2023-10-29T10:29:25.711030Z","shell.execute_reply":"2023-10-29T10:29:25.719367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=2)\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=2)\n        self.max_pool = nn.MaxPool2d(kernel_size=2)\n        self.avg_pool = nn.AvgPool2d(kernel_size=2)\n        self.fc = nn.Linear(in_features=64*4*4, out_features=2)\n        \n    def forward(self, x):\n        x = self.max_pool(F.relu(self.conv1(x)))\n        x = self.max_pool(F.relu(self.conv2(x)))\n        x = self.avg_pool(x)\n        x = x.view(-1, 64*4*4)\n        x = self.fc(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:29:25.721363Z","iopub.execute_input":"2023-10-29T10:29:25.721577Z","iopub.status.idle":"2023-10-29T10:29:25.731448Z","shell.execute_reply.started":"2023-10-29T10:29:25.721552Z","shell.execute_reply":"2023-10-29T10:29:25.730650Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model().to(device)\nmodel","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:29:25.732509Z","iopub.execute_input":"2023-10-29T10:29:25.732788Z","iopub.status.idle":"2023-10-29T10:29:32.683663Z","shell.execute_reply.started":"2023-10-29T10:29:25.732745Z","shell.execute_reply":"2023-10-29T10:29:32.682785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4) 모델 훈련 ","metadata":{}},{"cell_type":"markdown","source":"손실 함수 설정","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:29:32.684662Z","iopub.execute_input":"2023-10-29T10:29:32.684891Z","iopub.status.idle":"2023-10-29T10:29:32.689021Z","shell.execute_reply.started":"2023-10-29T10:29:32.684863Z","shell.execute_reply":"2023-10-29T10:29:32.688248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"옵티마이저 설정","metadata":{}},{"cell_type":"code","source":"optimizer = torch.optim.SGD(model.parameters(), lr=0.01)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:29:32.690230Z","iopub.execute_input":"2023-10-29T10:29:32.690519Z","iopub.status.idle":"2023-10-29T10:29:32.699868Z","shell.execute_reply.started":"2023-10-29T10:29:32.690483Z","shell.execute_reply":"2023-10-29T10:29:32.699112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"모델 훈련","metadata":{}},{"cell_type":"code","source":"epochs = 10\n\nfor epoch in range(epochs):\n    epoch_loss = 0\n    \n    for images, labels in loader_train:\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        optimizer.zero_grad()\n        \n        outputs = model(images)\n        \n        loss = criterion(outputs, labels)\n        \n        epoch_loss += loss.item()\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n    print(f'epoch [{epoch + 1}/{epochs}] - 손실값 : {epoch_loss/len(loader_train):.4f}')","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:29:32.701091Z","iopub.execute_input":"2023-10-29T10:29:32.701403Z","iopub.status.idle":"2023-10-29T10:30:37.090582Z","shell.execute_reply.started":"2023-10-29T10:29:32.701362Z","shell.execute_reply":"2023-10-29T10:30:37.089749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5) 성능 검증","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\ntrue_list = []\npreds_list = []","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:30:37.091721Z","iopub.execute_input":"2023-10-29T10:30:37.091969Z","iopub.status.idle":"2023-10-29T10:30:37.095989Z","shell.execute_reply.started":"2023-10-29T10:30:37.091939Z","shell.execute_reply":"2023-10-29T10:30:37.095252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\n\nwith torch.no_grad():\n    for images, labels in loader_valid:\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(images)\n        preds = torch.softmax(outputs.cpu(), dim=1)[:, 1]\n        true = labels.cpu()\n        \n        preds_list.extend(preds)\n        true_list.extend(true)\nprint(f'검증 데이터 ROC AUC : {roc_auc_score(true_list, preds_list):.4f}')","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:38:12.684175Z","iopub.execute_input":"2023-10-29T10:38:12.684491Z","iopub.status.idle":"2023-10-29T10:38:13.344938Z","shell.execute_reply.started":"2023-10-29T10:38:12.684458Z","shell.execute_reply":"2023-10-29T10:38:13.344143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6) 예측 및 결과 제출","metadata":{}},{"cell_type":"code","source":"dataset_test = ImageDataset(df=submission, img_dir='test/', transform=transform)\nloader_test = DataLoader(dataset=dataset_test, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:41:12.930680Z","iopub.execute_input":"2023-10-29T10:41:12.931011Z","iopub.status.idle":"2023-10-29T10:41:12.936119Z","shell.execute_reply.started":"2023-10-29T10:41:12.930979Z","shell.execute_reply":"2023-10-29T10:41:12.935272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\n\npreds = []\n\nwith torch.no_grad():\n    for images, _ in loader_test:\n        images = images.to(device)\n        outputs = model(images)\n        preds_part = torch.softmax(outputs.cpu(), dim=1)[:, 1].tolist()\n        preds.extend(preds_part)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:45:01.772690Z","iopub.execute_input":"2023-10-29T10:45:01.773564Z","iopub.status.idle":"2023-10-29T10:45:03.187945Z","shell.execute_reply.started":"2023-10-29T10:45:01.773519Z","shell.execute_reply":"2023-10-29T10:45:03.187332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['has_cactus'] = preds\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:47:43.051066Z","iopub.execute_input":"2023-10-29T10:47:43.051700Z","iopub.status.idle":"2023-10-29T10:47:43.078867Z","shell.execute_reply.started":"2023-10-29T10:47:43.051659Z","shell.execute_reply":"2023-10-29T10:47:43.078146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\nshutil.rmtree('./train')\nshutil.rmtree('./test')","metadata":{"execution":{"iopub.status.busy":"2023-10-29T10:49:15.704413Z","iopub.execute_input":"2023-10-29T10:49:15.704707Z","iopub.status.idle":"2023-10-29T10:49:16.364060Z","shell.execute_reply.started":"2023-10-29T10:49:15.704678Z","shell.execute_reply":"2023-10-29T10:49:16.363378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. 성능 개선\n### 1) 데이터 준비","metadata":{}},{"cell_type":"code","source":"import torch\nimport random\nimport numpy as np\nimport os\n\nseed = 50\nos.environ['PYTHONHASHSEED'] = str(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.enabled = False\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\n\nimport pandas as pd\n\ndata_path = '/kaggle/input/aerial-cactus-identification/'\n\nlabels = pd.read_csv(data_path + 'train.csv')\nsubmission = pd.read_csv(data_path + 'sample_submission.csv')\n\n\nfrom zipfile import ZipFile\n\nwith ZipFile(data_path + 'train.zip') as zipper:\n    zipper.extractall()\n    \nwith ZipFile(data_path + 'test.zip') as zipper:\n    zipper.extractall()\n    \n\nfrom sklearn.model_selection import train_test_split\n\ntrain, valid = train_test_split(labels, test_size=0.1, stratify=labels['has_cactus'], random_state=50)\n\n\n\nimport cv2\nfrom torch.utils.data import Dataset\n\nclass ImageDataset(Dataset):\n    def __init__(self, df, img_dir='./', transform=None):\n        super().__init__()\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        img_id = self.df.iloc[idx, 0]\n        img_path = self.img_dir + img_id\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        label = self.df.iloc[idx, 1]\n        \n        if self.transform is not None:\n            image = self.transform(image)\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2023-10-29T13:14:10.319932Z","iopub.execute_input":"2023-10-29T13:14:10.320573Z","iopub.status.idle":"2023-10-29T13:14:22.009490Z","shell.execute_reply.started":"2023-10-29T13:14:10.320490Z","shell.execute_reply":"2023-10-29T13:14:22.008843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"이미지 변환기 정의","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms\n\ntransform_train = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Pad(32, padding_mode='symmetric'),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(10),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Pad(32, padding_mode='symmetric'),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n])","metadata":{"execution":{"iopub.status.busy":"2023-10-29T13:14:22.010914Z","iopub.execute_input":"2023-10-29T13:14:22.011122Z","iopub.status.idle":"2023-10-29T13:14:22.268045Z","shell.execute_reply.started":"2023-10-29T13:14:22.011098Z","shell.execute_reply":"2023-10-29T13:14:22.267282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"데이터셋 및 데이터 로더 생성","metadata":{}},{"cell_type":"code","source":"dataset_train = ImageDataset(df=train, img_dir='train/', transform=transform_train)\ndataset_valid = ImageDataset(df=valid, img_dir='train/', transform=transform_test)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T13:14:22.269277Z","iopub.execute_input":"2023-10-29T13:14:22.269565Z","iopub.status.idle":"2023-10-29T13:14:22.274587Z","shell.execute_reply.started":"2023-10-29T13:14:22.269525Z","shell.execute_reply":"2023-10-29T13:14:22.273869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nloader_train = DataLoader(dataset=dataset_train, batch_size=32, shuffle=True)\nloader_valid = DataLoader(dataset=dataset_valid, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T13:14:22.276517Z","iopub.execute_input":"2023-10-29T13:14:22.276858Z","iopub.status.idle":"2023-10-29T13:14:22.288038Z","shell.execute_reply.started":"2023-10-29T13:14:22.276819Z","shell.execute_reply":"2023-10-29T13:14:22.287430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2) 모델 생성","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.layer1 = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=2),\n            nn.BatchNorm2d(32),\n            nn.LeakyReLU(),\n            nn.MaxPool2d(kernel_size=2))\n        \n        self.layer2 = nn.Sequential(\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=2),\n            nn.BatchNorm2d(64),\n            nn.LeakyReLU(),\n            nn.MaxPool2d(kernel_size=2))\n        \n        self.layer3 = nn.Sequential(\n            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=2),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(),\n            nn.MaxPool2d(kernel_size=2))\n        \n        self.layer4 = nn.Sequential(\n            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=2),\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(),\n            nn.MaxPool2d(kernel_size=2))\n        \n        self.layer5 = nn.Sequential(\n            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=2),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(),\n            nn.MaxPool2d(kernel_size=2))\n        \n        self.avg_pool = nn.AvgPool2d(kernel_size=4)\n        \n        self.fc1 = nn.Linear(in_features=512*1*1, out_features=64)\n        self.fc2 = nn.Linear(in_features=64, out_features=2)\n        \n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.layer5(x)\n        x = self.avg_pool(x)\n        x = x.view(-1, 512*1*1)\n        x = self.fc1(x)\n        x = self.fc2(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-10-29T13:14:22.288944Z","iopub.execute_input":"2023-10-29T13:14:22.289152Z","iopub.status.idle":"2023-10-29T13:14:22.305334Z","shell.execute_reply.started":"2023-10-29T13:14:22.289125Z","shell.execute_reply":"2023-10-29T13:14:22.304695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model().to(device)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T13:14:22.306484Z","iopub.execute_input":"2023-10-29T13:14:22.306876Z","iopub.status.idle":"2023-10-29T13:14:32.402139Z","shell.execute_reply.started":"2023-10-29T13:14:22.306837Z","shell.execute_reply":"2023-10-29T13:14:32.401367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3) 모델 훈련","metadata":{}},{"cell_type":"markdown","source":"손실 함수와 옵티마이저 설정","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T13:14:32.403226Z","iopub.execute_input":"2023-10-29T13:14:32.403511Z","iopub.status.idle":"2023-10-29T13:14:32.408213Z","shell.execute_reply.started":"2023-10-29T13:14:32.403482Z","shell.execute_reply":"2023-10-29T13:14:32.407007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adamax(model.parameters(), lr=0.00006)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T13:14:32.409349Z","iopub.execute_input":"2023-10-29T13:14:32.409574Z","iopub.status.idle":"2023-10-29T13:14:32.424097Z","shell.execute_reply.started":"2023-10-29T13:14:32.409552Z","shell.execute_reply":"2023-10-29T13:14:32.423371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"모델 훈련","metadata":{}},{"cell_type":"code","source":"epochs = 70\n\nfor epoch in range(epochs):\n    epoch_loss = 0\n    \n    for images, labels in loader_train:\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        optimizer.zero_grad()\n        \n        outputs = model(images)\n        \n        loss = criterion(outputs, labels)\n        \n        epoch_loss += loss.item()\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n    print(f'epoch [{epoch + 1}/{epochs}] - 손실값 : {epoch_loss/len(loader_train):.4f}')","metadata":{"execution":{"iopub.status.busy":"2023-10-29T13:28:43.918305Z","iopub.execute_input":"2023-10-29T13:28:43.919157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4) 성능 검증","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\ntrue_list = []\npreds_list = []\n\nmodel.eval()\n\nwith torch.no_grad():\n    for images, labels in loader_valid:\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(images)\n        preds = torch.softmax(outputs.cpu(), dim=1)[:, 1]\n        true = labels.cpu()\n        \n        preds_list.extend(preds)\n        true_list.extend(true)\nprint(f'검증 데이터 ROC AUC : {roc_auc_score(true_list, preds_list):.4f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5) 예측 및 결과 제출","metadata":{}},{"cell_type":"code","source":"dataset_test = ImageDataset(df=submission, img_dir='test/', transform=transform_test)\nloader_test = DataLoader(dataset=dataset_test, batch_size=32, shuffle=False)\n\nmodel.eval()\n\npreds = []\n\nwith torch.no_grad():\n    for images, _ in loader_test:\n        images = images.to(device)\n        \n        outputs = model(images)\n        preds_part = torch.softmax(outputs.cpu(), dim=1)[:, 1].tolist()\n        preds.extend(preds_part)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['has_cactus'] = preds\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\nshutil.rmtree('./train')\nshutil.rmtree('./test')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"한 걸음 더","metadata":{}},{"cell_type":"code","source":"import torch\nimport random\nimport numpy as np\nimport os\n\nseed = 50\nos.environ['PYTHONHASHSEED'] = str(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.enabled = False\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\n\nimport pandas as pd\n\ndata_path = '/kaggle/input/aerial-cactus-identification/'\n\nlabels = pd.read_csv(data_path + 'train.csv')\nsubmission = pd.read_csv(data_path + 'sample_submission.csv')\n\n\nfrom zipfile import ZipFile\n\nwith ZipFile(data_path + 'train.zip') as zipper:\n    zipper.extractall()\n    \nwith ZipFile(data_path + 'test.zip') as zipper:\n    zipper.extractall()\n    \n\ntrain = labels\n\n\nimport cv2\nfrom torch.utils.data import Dataset\n\nclass ImageDataset(Dataset):\n    def __init__(self, df, img_dir='./', transform=None):\n        super().__init__()\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        img_id = self.df.iloc[idx, 0]\n        img_path = self.img_dir + img_id\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        label = self.df.iloc[idx, 1]\n        \n        if self.transform is not None:\n            image = self.transform(image)\n        return image, label\n\nfrom torchvision import transforms\n\ntransform_train = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Pad(32, padding_mode='symmetric'),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(10),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Pad(32, padding_mode='symmetric'),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n])\n\ndataset_train = ImageDataset(df=train, img_dir='train/', transform=transform_train)\n\nfrom torch.utils.data import DataLoader\n\nloader_train = DataLoader(dataset=dataset_train, batch_size=32, shuffle=True)\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.layer1 = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=2),\n            nn.BatchNorm2d(32),\n            nn.LeakyReLU(),\n            nn.MaxPool2d(kernel_size=2))\n        \n        self.layer2 = nn.Sequential(\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=2),\n            nn.BatchNorm2d(64),\n            nn.LeakyReLU(),\n            nn.MaxPool2d(kernel_size=2))\n        \n        self.layer3 = nn.Sequential(\n            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=2),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(),\n            nn.MaxPool2d(kernel_size=2))\n        \n        self.layer4 = nn.Sequential(\n            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=2),\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(),\n            nn.MaxPool2d(kernel_size=2))\n        \n        self.layer5 = nn.Sequential(\n            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=2),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(),\n            nn.MaxPool2d(kernel_size=2))\n        \n        self.avg_pool = nn.AvgPool2d(kernel_size=4)\n        \n        self.fc1 = nn.Linear(in_features=512*1*1, out_features=64)\n        self.fc2 = nn.Linear(in_features=64, out_features=2)\n        \n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.layer5(x)\n        x = self.avg_pool(x)\n        x = x.view(-1, 512*1*1)\n        x = self.fc1(x)\n        x = self.fc2(x)\n        return x\n\nmodel = Model().to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adamax(model.parameters(), lr=0.00006)\n\nepochs = 70\n\nfor epoch in range(epochs):\n    epoch_loss = 0\n    \n    for images, labels in loader_train:\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        optimizer.zero_grad()\n        \n        outputs = model(images)\n        \n        loss = criterion(outputs, labels)\n        \n        epoch_loss += loss.item()\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n    print(f'epoch [{epoch + 1}/{epochs}] - 손실값 : {epoch_loss/len(loader_train):.4f}')\n\n\ndataset_test = ImageDataset(df=submission, img_dir='test/', transform=transform_test)\nloader_test = DataLoader(dataset=dataset_test, batch_size=32, shuffle=False)\n\nmodel.eval()\n\npreds = []\n\nwith torch.no_grad():\n    for images, _ in loader_test:\n        images = images.to(device)\n        \n        outputs = model(images)\n        preds_part = torch.softmax(outputs.cpu(), dim=1)[:, 1].tolist()\n        preds.extend(preds_part)\n\nsubmission['has_cactus'] = preds\nsubmission.to_csv('submission.csv', index=False)\n\nimport shutil\n\nshutil.rmtree('./train')\nshutil.rmtree('./test')","metadata":{},"execution_count":null,"outputs":[]}]}